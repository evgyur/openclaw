# Code Review with `/grill`

**Pre-PR code review powered by AI ‚Äî catch bugs, security issues, and style problems before CI runs.**

---

## Why Pre-PR Review Matters

Traditional code review happens **after** you open a PR:
- CI pipelines take minutes (or hours) to run
- Reviewers are busy or in different time zones
- You've already context-switched to the next task
- Fixing issues requires another review cycle

**`/grill` changes this:**

‚úÖ **Instant feedback** ‚Äî get results in seconds, not hours  
‚úÖ **Catch issues early** ‚Äî before CI runs or reviewers see your code  
‚úÖ **Learn faster** ‚Äî understand *why* something is flagged  
‚úÖ **Save reviewer time** ‚Äî fewer rounds of feedback  
‚úÖ **Ship with confidence** ‚Äî know your code is solid before pushing

---

## Command Reference

### Basic usage

```bash
# Review unstaged changes
openclaw grill

# Review specific files
openclaw grill src/api/users.ts src/utils/validators.ts

# Review all TypeScript files
openclaw grill '**/*.ts'
```

### Flags

#### `--strict`
Enable stricter thresholds ‚Äî surfaces more CONSIDER and NIT-level issues.

```bash
openclaw grill --strict
```

**Use when:**
- You're working on critical code (auth, payments, security)
- You want to learn best practices
- You have time to address minor improvements

**Skip when:**
- You need quick validation for a prototype
- You're doing exploratory work

---

#### `--focus=<area>`
Focus the review on a specific area.

```bash
# Security-focused review
openclaw grill --focus=security

# Performance-focused review
openclaw grill --focus=performance

# Maintainability-focused review
openclaw grill --focus=maintainability
```

**Available focus areas:**
- `security` ‚Äî Auth, input validation, injection risks, secrets
- `performance` ‚Äî Algorithmic complexity, memory usage, database queries
- `maintainability` ‚Äî Code clarity, duplication, naming, structure
- `correctness` ‚Äî Logic errors, edge cases, type safety
- `style` ‚Äî Formatting, conventions, idiomatic patterns

**Combine multiple areas:**
```bash
openclaw grill --focus=security,performance
```

---

#### `--output=<format>`
Control output format.

```bash
# Default: terminal-friendly with colors
openclaw grill

# JSON for CI integration
openclaw grill --output=json

# Markdown for GitHub PR comments
openclaw grill --output=markdown > review.md
```

---

#### `--severity=<level>`
Set minimum severity to display.

```bash
# Only show critical issues
openclaw grill --severity=MUST_FIX

# Show everything including nitpicks
openclaw grill --severity=NIT
```

---

## Interpreting Results

`/grill` categorizes findings into three severity levels:

### üî¥ MUST_FIX
**Critical issues that will likely break production or introduce security vulnerabilities.**

Examples:
- SQL injection vulnerabilities
- Unhandled promise rejections in critical paths
- Authentication bypass bugs
- Memory leaks in long-running processes
- Type errors that will cause runtime crashes

**Action:** Fix these before merging. No exceptions.

---

### üü° CONSIDER
**Issues that may cause problems in specific scenarios or violate best practices.**

Examples:
- Missing error handling in edge cases
- Inefficient algorithms that work but don't scale
- Unclear variable names that hurt readability
- Missing input validation (non-critical paths)
- Potential race conditions

**Action:** Evaluate context. Fix if:
- The code path is frequently used
- The issue affects user experience
- The fix is straightforward

Skip if:
- It's a prototype or internal tool
- The scenario is genuinely edge-case
- The refactor would introduce complexity

---

### üü¢ NIT
**Style preferences, minor improvements, or suggestions for idiomatic code.**

Examples:
- Consistent naming conventions
- Simplifying logic with language features (e.g., optional chaining)
- Moving magic numbers to constants
- Adding helpful comments
- Formatting improvements

**Action:** Optional. Fix when:
- You're already editing nearby code
- You want to learn better patterns
- The codebase has strict style guidelines

---

## Example Output

```
üîç Reviewing src/api/users.ts...

üî¥ MUST_FIX: SQL Injection Risk (line 45)
  ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
  ‚îÇ const query = `SELECT * FROM users WHERE id = ${userId}` ‚îÇ
  ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
  
  Problem: User input is directly interpolated into SQL query
  Impact: Attackers can execute arbitrary SQL commands
  Fix: Use parameterized queries
  
  ‚úÖ Suggested:
  const query = `SELECT * FROM users WHERE id = ?`
  db.execute(query, [userId])

üü° CONSIDER: Missing Error Handling (line 78)
  ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
  ‚îÇ const data = await fetchUserData(userId);   ‚îÇ
  ‚îÇ return res.json(data);                      ‚îÇ
  ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
  
  Problem: Network request can fail but no try/catch
  Impact: Unhandled promise rejection crashes the server
  Fix: Wrap in try/catch and return appropriate error response

üü¢ NIT: Inconsistent Naming (line 92)
  ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
  ‚îÇ const usr = await getUser(); ‚îÇ
  ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
  
  Suggestion: Use full word 'user' for consistency with codebase

‚úÖ Review complete
  ‚Ä¢ 1 MUST_FIX
  ‚Ä¢ 1 CONSIDER
  ‚Ä¢ 1 NIT
```

---

## Integration with GitHub PRs

### Generate PR comment
```bash
# Run grill and save markdown output
openclaw grill --output=markdown > review.md

# Post as PR comment (requires gh CLI)
gh pr comment <PR_NUMBER> --body-file review.md
```

### CI Integration
Add to your GitHub Actions workflow:

```yaml
name: AI Code Review
on: pull_request

jobs:
  grill:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Install OpenClaw
        run: npm install -g openclaw
      
      - name: Run grill
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          openclaw grill --output=json > grill-results.json
          
      - name: Check for MUST_FIX issues
        run: |
          if grep -q '"severity":"MUST_FIX"' grill-results.json; then
            echo "‚ùå MUST_FIX issues found"
            exit 1
          fi
          
      - name: Post results
        if: always()
        run: |
          openclaw grill --output=markdown > review.md
          gh pr comment ${{ github.event.pull_request.number }} --body-file review.md
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

---

## Tips & Best Practices

### 1. Run grill before committing
Add to your pre-commit hook:

```bash
#!/bin/bash
# .git/hooks/pre-commit

echo "Running grill..."
if ! openclaw grill --severity=MUST_FIX; then
  echo "‚ùå MUST_FIX issues found. Commit blocked."
  exit 1
fi
```

### 2. Use --focus for targeted reviews
If you're only touching auth code:
```bash
openclaw grill src/auth/*.ts --focus=security
```

### 3. Review incrementally
Don't wait until you have 500+ lines of changes:
```bash
# Review after each logical chunk
git add src/api/users.ts
openclaw grill src/api/users.ts
```

### 4. Learn from NITs
Even if you don't fix every NIT, read them ‚Äî they teach you patterns and idioms you might not know.

### 5. Combine with linters
`/grill` complements (doesn't replace) ESLint, Prettier, etc.
- **Linters** catch syntax and style
- **`/grill`** catches logic, security, and architectural issues

---

## Limitations

`/grill` is powerful but not perfect:

‚ùå **Cannot replace human reviewers** ‚Äî context, design decisions, and business logic still need human judgment  
‚ùå **May miss issues** ‚Äî AI can hallucinate or miss edge cases  
‚ùå **May flag false positives** ‚Äî especially in strict mode  
‚ùå **Limited to visible code** ‚Äî doesn't understand external dependencies or runtime behavior  

**Best practice:** Use `/grill` as a first pass, then have humans review.

---

## FAQ

**Q: Does grill modify my code?**  
A: No. It only analyzes and reports findings. You decide what to fix.

**Q: What models does it use?**  
A: By default, Claude Sonnet 4 for speed and cost. You can configure this in `~/.clawdbot/config.json5`.

**Q: How much does it cost?**  
A: Roughly $0.01‚Äì$0.05 per review (depends on file size and model). See [FAQ](./faq.md#cost-considerations).

**Q: Can I customize the review criteria?**  
A: Yes. See `grillDefaults` in your config file.

**Q: Does it work with languages other than TypeScript?**  
A: Yes ‚Äî Python, Go, Rust, Java, etc. The quality of feedback depends on the model's training.

---

## Next Steps

- **[Using Subagents](./use-subagents.md)** ‚Äî Learn how grill spawns subagents under the hood
- **[Opus Guard](./opus-guard.md)** ‚Äî Understand the safety layer
- **[FAQ](./faq.md)** ‚Äî More questions about performance and debugging
